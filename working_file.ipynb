{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0714a5-6040-424c-96ea-10def5a2f709",
   "metadata": {},
   "source": [
    "# Job Description Analyzer\n",
    "\n",
    "As part of this project, we have been given a few job descriptions each having its own set of requirements. The aim of the project is to use simple python and some simple text processing to analyze these job descriptions and get a list of the most desirable skills in the industry.\n",
    "\n",
    "To do that, please answer the questions that follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c2225-a6fc-4eaf-8cb4-6e42bd1d7b0b",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0956f-9f0f-4ba1-b6a2-67a6aed5a5c9",
   "metadata": {},
   "source": [
    "#### Q1: All the required files can be found in the `files` folder. One of the files is called `BusinessAnalyst.txt`. Using simple python file handling, read the contents of that file and save in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84f4719-4c2c-41e8-8941-32ccb78b1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Business Analyst will gather requirements, prepare documentation, and collaborate with developers. Required skills include SQL, Excel, problem-solving, communication, and knowledge of ERP systems.\n"
     ]
    }
   ],
   "source": [
    "with open(\"files/BussinessAnalyst.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173a3e3-5423-4909-8b5c-535d277bfd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f7dfa-4814-47e8-b335-b4fcada32076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b05cc120-2441-40fc-b785-9adb2ffedb84",
   "metadata": {},
   "source": [
    "Now, we must read all the files. Here, since there is no common naming convention followed, it can be cumbersome to get the names of all files manually. Here, we can use the `os` module.\n",
    "\n",
    "#### Q2: use the `os.listdir()` function to get the names of all files to read automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8c2312-b4f5-4ac1-84cc-d745e208f600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BussinessAnalyst.txt',\n",
       " 'DataAnalyst1.txt',\n",
       " 'DeveloperFresher.txt',\n",
       " 'ML_Engineer.txt',\n",
       " 'ProjectManager.txt',\n",
       " 'PythonDeveloper1.txt',\n",
       " 'security_analyst.txt',\n",
       " 'SoftwareEngineer.txt',\n",
       " 'SoftwareEngineer2.txt',\n",
       " 'SQL_developer.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_names = os.listdir(\"files\")\n",
    "file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f21c9e-d027-4723-b65d-9c61f6a8ec14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2b707-0778-4f7a-9294-741ef2b6d79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ebdb5dd-a518-48c2-8db7-e835bc48656c",
   "metadata": {},
   "source": [
    "#### Q3: Now using a for loop, read all these files and save their contents in a list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0eb55c-bb98-4195-a37a-39bf8fccea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts = []\n",
    "\n",
    "for file in file_names:\n",
    "    with open(\"files/\" + file, \"r\") as f:\n",
    "        all_texts.append(f.read())\n",
    "\n",
    "len(all_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21614ec7-f31d-4a92-9ed5-bb2d5276c036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2873242-50a9-4721-aed4-a341851e1224",
   "metadata": {},
   "source": [
    "#### Q4. Wrap this entire logic of reading all files into a function called `load_job_descriptions` that returns the contents list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a113c9-8237-45b7-906f-1364274a7454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_job_descriptions(folder_path=\"files\"):\n",
    "    texts = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        with open(folder_path + \"/\" + file, \"r\") as f:\n",
    "            texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "job_descriptions = load_job_descriptions()\n",
    "len(job_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5ddbb-e648-4105-b8e0-1710dca6c5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ead05e-3e0c-44e5-8673-13c44f7f797d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db685034-561d-4afe-b4f1-b73bbd94dc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b74a46-90af-4370-a2d9-f1bee18babaa",
   "metadata": {},
   "source": [
    "### Cleaning text data for analysis\n",
    "\n",
    "Now the second part of this mini project is to clean the job descriptions so that we can get some meaningful insights. We plan on doing a simple count-based analysis, where we will just figure out the most-frequently occuring words/skills in these files.\n",
    "\n",
    "\n",
    "To make that analysis meaningful, we must apply cleaning steps including making everything of the same case, removing special characters like period(.), commas(,), etc. Also very important, we would need to remove frequently occuring words that don't provide any context as these words would have the highest counts but they don't provide any content. lets start one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2793337-d173-41e1-a90e-a2b8a36fd8e6",
   "metadata": {},
   "source": [
    "#### Q5. Create a function to clean job descriptions. This function should take one job description at a time, it should make everything lowercase and remove special characters including period(.), commas(,), and round brackets. Finally, it should split the text into words and return that list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c257209-6644-41c2-ace6-20eafc369e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_job_description(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\",\"\",text)\n",
    "    words = text.split()\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c0478-7c55-45e7-bcb3-80208e2ad3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad6886ce-e336-48d4-9a4d-1f82f64d97d5",
   "metadata": {},
   "source": [
    "#### Q6. Now `map` this function to each job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556af4c7-6b1c-47da-8284-9644f022a080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cleaned_descriptions = []\n",
    "for jd in job_descriptions:\n",
    "    cleaned_descriptions.append(clean_job_description(jd))\n",
    "len(cleaned_descriptions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c52b3-61ff-4c2d-bfec-42bb1ae3311a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad27b3-e5ce-4a95-969a-da1b3731418c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832fcd2-5d05-4540-a42c-5f53041af2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55c61086-4d95-4ab4-bb8c-17a61270954a",
   "metadata": {},
   "source": [
    "#### Q7. Since we will need the most common skills across all these job descriptions, create a single list of all words from all job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "323f4183-0067-4375-b8ab-71114488d872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_words = []\n",
    "\n",
    "for words in cleaned_descriptions:\n",
    "    all_words.extend(words)\n",
    "len(all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad076f-1a04-4557-a7be-d364cdad2296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a5f78-917c-4647-870e-04614dbe9f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baadf12-2c22-4c5f-91e0-789b2876a87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de9ce240-1ed1-4ef7-bea2-3fb0529a3e3f",
   "metadata": {},
   "source": [
    "#### Q8: Now before we start counting the number of occurences of each of these words, we must first remove common english language words as they will have really high counts but we don't need them in our analysis. Remove the below list of words from our all_words list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cec05ae-f671-4309-b423-839313ec59fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = [\"and\",\"the\",\"to\",\"with\",\"a\",\"of\",\"in\",\"for\",\"is\",\"on\",\"or\",\"an\",\"using\",\"such\",\"as\", \"we\", \"need\", \"will\", \"are\", \"also\",\"be\",\n",
    "            \"it\",\"include\", \"skills\"]\n",
    "            \n",
    "filtered_words = []\n",
    "\n",
    "for word in all_words:\n",
    "    if word not in stopwords:\n",
    "        filtered_words.append(word)\n",
    "len(filtered_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb01f4-6eb2-4b24-b507-e17cdc8324fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201babd6-fff5-458f-baa6-dc9edbe2cdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e89b6f-ec86-434b-ab87-184e7c068975",
   "metadata": {},
   "source": [
    "#### Q9: Finally, create a function that takes in a list of words and returns their word counts as a dictionary where the word is key and the count is value. Also sort that dictionary based on word counts using the `sorted` function in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7ef02d-cd3d-4068-adbd-94e47388ddb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 6),\n",
       " ('required', 4),\n",
       " ('sql', 4),\n",
       " ('knowledge', 4),\n",
       " ('data', 4),\n",
       " ('experience', 4),\n",
       " ('communication', 3),\n",
       " ('looking', 3),\n",
       " ('design', 3),\n",
       " ('engineer', 3),\n",
       " ('candidate', 3),\n",
       " ('strong', 3),\n",
       " ('cloud', 3),\n",
       " ('business', 2),\n",
       " ('analyst', 2),\n",
       " ('excel', 2),\n",
       " ('problemsolving', 2),\n",
       " ('datasets', 2),\n",
       " ('tools', 2),\n",
       " ('like', 2)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(words_list):\n",
    "    counts = {}\n",
    "\n",
    "    for word in words_list:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    sorted_counts = dict(\n",
    "        sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "    )\n",
    "\n",
    "    return sorted_counts\n",
    "word_counts = word_count(filtered_words)\n",
    "list(word_counts.items())[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ba89a-608e-4a4a-a7b4-cab818d6c859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47057cac-aa31-493a-89d8-7054a77d94a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2a5ca-319e-4d99-b78a-c3175e2eeec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dab029c0-78d9-4ebf-a613-1b031b4b7c59",
   "metadata": {},
   "source": [
    "#### Q10: Here we can see that the top occuring words are giving some context and the top skills required in the industry. However, there are still some irrelevant words that are not skills.\n",
    "\n",
    "#### To make this even better, filter the above word counts to only include those key value pairs where the key is a skill as per the below skills list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19c67904-45b9-4899-9d3a-47d6622ac5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python': 6,\n",
       " 'sql': 4,\n",
       " 'html': 1,\n",
       " 'css': 1,\n",
       " 'javascript': 1,\n",
       " 'scripting': 2,\n",
       " 'git': 2,\n",
       " 'cloud': 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = ['python', 'sql', 'powerbi', 'html', 'css', 'javascript', 'scripting', 'git', 'problem-solving', 'cloud']\n",
    "\n",
    "skill_counts = {}\n",
    "\n",
    "for skill in skills:\n",
    "    if skill in word_counts:\n",
    "        skill_counts[skill] = word_counts[skill]\n",
    "\n",
    "skill_counts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b554ba7-08ec-4b95-a55e-0c11b3e41127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be08f10-e18a-4e75-be06-40eac5b26d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2437bf3-b65a-42e2-8f24-a11bf08a6973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca8107-48c5-448f-a880-59cb13801af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04b21b-4943-428c-a60d-774f598dc110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19b52830-6a93-4c91-b128-fad194383922",
   "metadata": {},
   "source": [
    "#### Bonus Question: Now package this entire program into a single .py script that takes in the folder location of where the files to read are and outputs the top skills demanded in the industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd2bf21d-d985-4526-bbb3-2a989e626f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import sys\n",
    "SKILLS = [\n",
    "    \"python\", \"sql\", \"excel\", \"power bi\", \"tableau\",\n",
    "    \"machine learning\", \"data analysis\", \"pandas\",\n",
    "    \"numpy\", \"statistics\", \"communication\"\n",
    "]\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def extract_skills(text):\n",
    "    found = []\n",
    "    for skill in SKILLS:\n",
    "        if skill in text:\n",
    "            found.append(skill)\n",
    "    return found\n",
    "\n",
    "def read_files_from_folder(folder_path):\n",
    "    all_text = \"\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                all_text += file.read() + \" \"\n",
    "\n",
    "    return all_text\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python skills_extractor.py <folder_path>\")\n",
    "        return\n",
    "\n",
    "    folder_path = sys.argv[1]\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(\"Folder does not exist.\")\n",
    "        return\n",
    "\n",
    "    print(\"Reading files...\")\n",
    "\n",
    "    text = read_files_from_folder(folder_path)\n",
    "    text = clean_text(text)\n",
    "\n",
    "    skills_found = extract_skills(text)\n",
    "    skill_counts = Counter(skills_found)\n",
    "\n",
    "    print(\"\\nTop Skills Demanded:\\n\")\n",
    "\n",
    "    for skill, count in skill_counts.most_common(10):\n",
    "        print(f\"{skill.title()} - {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90501e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
